# Data Scrubbing and Cleaning for Improved Analysis with DataCleaner

![image](https://github.com/westrany/Data-Scrubbing-and-Cleaning-for-Improved-Analysis-with-Python/assets/69496007/8b8c009c-dcb5-4c1e-bcb8-cc3821423902)

## Objective  

Demonstrate proficiency in data cleaning techniques using DataCleaner, a third-party library based on Pandas DataFrame that employs a distinctive method, merging conventional data cleaning processes and automating them, resulting in significant time and effort savings.  

The project aims to prepare raw datasets for analysis by addressing inconsistencies, missing values, outliers, and other data quality issues.

## Dataset Selection  

1. Choose a couple of datasets from a reliable source such as Kaggle, UCI Machine Learning Repository, or government databases. Ensure they represent different types of data (e.g., tabular, time series, text).  

2. Select datasets with noticeable data quality issues like missing values, duplicate entries, inconsistent formats, or outliers.

## Tools  

• DataCleaner library for data manipulation and cleaning.

## Key Steps  

1. **Data Collection:** Download the chosen datasets and load them into the Python environment.
   
2. **Initial Data Assessment:**
   
      • Explore the structure of the datasets (columns, data types, size)
   
      • Check for missing values, duplicate entries, and outliers.
   
      • Identify any inconsistencies or errors in data formats.
   
3. **Data Cleaning:**
   
      • Use DataCleaner's functionality to replace missing values with the mode or median on a column-wise basis.
   
      • Encode categorical variables using appropriate methods provided by DataCleaner.  

      • Remove rows with missing values using DataCleaner's automated features.  

      • Apply automatic discovery and correction of common data issues such as outliers and format errors using DataCleaner's built-in algorithms.  

   
4. **Data Transformation:**
   
      • Perform data transformations as necessary (e.g., normalization, log transformation), leveraging DataCleaner's capabilities.
   
      • Create derived features or variables that might enhance analysis.
   
8. **Data Validation:**
   
      • Validate the cleaned datasets to ensure that data quality issues have been addressed effectively.
   
      • Use DataCleaner's data quality assessment metrics and methods to assess data completeness, accuracy, consistency, etc.
   
      • Check for any unintended consequences of data cleaning operations.
   
10. **Documentation and Reporting:**
    
      • Document the data cleaning process, including the steps taken and rationale behind decisions, utilizing DataCleaner's visual interface if applicable.
    
      • Present summary statistics and visualizations to illustrate the improvements in data quality.
    
      • Prepare a report highlighting the impact of data cleaning on the analysis potential of the datasets.
    

## Additional Considerations  
1. Ensure reproducibility by documenting all code and steps taken in the cleaning process.
   
2. Consider leveraging DataCleaner's visual interface for easier data management and exploration.
   
3. Utilize DataCleaner's extensibility to integrate with other data processing and analysis tools if necessary.

## Conclusion  

By completing this project using DataCleaner, you will showcase your ability to efficiently address data quality issues and prepare datasets for analysis, demonstrating key skills valued in the field of data science.  


This project structure adheres to the principles of clear objectives, high-quality data, robust algorithms, interpretability, continuous improvement, cross-functional collaboration, and ethical considerations outlined in the guidelines, while leveraging the unique features of DataCleaner for data cleaning and transformation.  

### Research  

[My Favorite Python Libraries for Data Cleaning in 2023](https://medium.com/@tubelwj/my-favorite-python-libraries-for-data-cleaning-in-2023-c475830dacbb)

*MIT License, © Maria Fitas 2024*
